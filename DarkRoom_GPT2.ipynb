{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adventurer8/In-context-RL-with-AD/blob/main/DarkRoom_GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Отчёт**\n",
        "По заданию на вакансию [Intern Research Scientist](https://shell-lillipilli-1d0.notion.site/Intern-Research-Scientist-1eb13525009b419bb93d5181bfe695e2#df4bc384f00a47e1b37186ce51b882c0)"
      ],
      "metadata": {
        "id": "jIfGtrAUw86Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Часть 1: Research**"
      ],
      "metadata": {
        "id": "4udI_43Vxhr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Анализ статьи ([In-context RL with AD](https://arxiv.org/abs/2210.14215/))"
      ],
      "metadata": {
        "id": "NtgV7xb5w__b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9WZnRwgZjID"
      },
      "source": [
        "Статья зацепила. Чем? - раскажу во второй части задания.\n",
        "\n",
        "#### **1) Основные моменты статьи:**\n",
        "- Недостатком PD является то, что результирующая политика не улучшается постепенно от дополнительного взаимодействия со средой (не может улучшить свою политику в контексте путем проб и ошибок). Методы PD учат политики, но не алгоритмы RL\n",
        "\n",
        "- То есть, задача статьи - обучить трансформер **самой цели обучаться** (MetaRL), но за счет in-context\n",
        "\n",
        "- Для этого необходимы данные, отражающие последовательный прогресс в обучении, что гипотетически позволит моделировать сам процесс обучения с подкреплением как задачу предсказания причинно-следственной связи.\n",
        "\n",
        "- Трансформер должен быть способен включать в себе представление не только политики, но и **оператора улучшения политики**\n",
        "\n",
        "- DarkRoom: Для обучения оптимальному алгоритму необходимы многоэпизодические контексты из 2-4 эпизодов в 50-150 шагов.\n",
        "\n",
        "\n",
        "\n",
        "#### **2) Подумаем: Как из данных получить оператор?**\n",
        "\n",
        "На абстрактном уровне данные истории обучения одной задаче $h^i$ содержат\n",
        "\n",
        "$$ h^i = \\left\\{  {решение \\choose задачи}^i + {улучшение \\choose решения}^i +\\ обучение\\right\\} = \\left\\{\\widehat {P}^{\\ i}+\\widehat L^{\\ i}+\\widehat L\\right\\} $$\n",
        "\n",
        "Так как оператор обучения более абстрактный/обобщенный, чем сами политики, то для его отделения/выделения нужно \"диверсифицировать\" представления политик в данных $H$:\n",
        "\n",
        "$$ H = \\sum_i h^i\\ \\ \\Longleftrightarrow\\ \\ \\ \\bigcap_i h^i = \\widehat L$$\n",
        "\n",
        "Это сработает, если мы возьмем \"линейно независимые\" политики $\\widehat {P}^{\\ i}$, то есть л.н.з. задачи.\n",
        "\n",
        "- В качестве среды возьмем *DarkRoom*\n",
        "- В качестве модели RL возьмем самую простую *Q-Learning*\n",
        "\n",
        "В DarkRoom необходимо найти goal, бродя в пустой комнате размером $N$x$N$, и в течение нескольких эпизодов оптимизировать свою траекторию. Алгоритм QL в процессе обучения такой задачи по сути создает векторное поле в виде Q-table, со стоком в точке goal. Это векторное поле в процессе обучения постепенно приходит к состоянию, когда оно становиться градиентом скалярного поля формы конуса (V) вокруг точки goal (короче, как потенциальная яма/ложбина). В такой интерпретации, получается, что трансформер должен научиться постепенно отягощать точку с предположительным goal на потенциальной в среднем ровной поверхности (с неоднородной кривизной как учетом стохастичности - механизма любопытства). Каждый $goal$^i$ можно считать разной/л.н.з. задачей.\n",
        "\n",
        "Мы будем создавать истории $h^i$, включающие решение одной $i$-той задачи (start$\\rightarrow$goal$^i$). Такие политики будут достаточно л.н.з., и чем больше разных goal мы возьмем, тем большую диверсификацию получим.\n",
        "\n",
        "#### **3) Об операторе обучения**\n",
        "\n",
        "> Политика RL улучшается на протяжении всей истории обучения. Поэтому, точное предсказание действий требует, чтобы модель AD не только выводила текущую политику из контекста, но и её улучшенные версии, таким образом выделяя оператор улучшения политики.\n",
        "\n",
        "В нашей задаче оператор обучения $\\widehat L$, по сути, превращается в оператор укорачивания траектории между фиксированными start$\\rightarrow$finish, буквально до прямой. Поэтому, за критерий улучшения в нашей среде возьмем тенденцию в сокращении длинны успешных эпизодов.\n",
        "\n",
        "На заметку:\n",
        "\n",
        "> Под контекстным обучением понимается способность выводить задачи из контекста (например, LLM могут быть направлены на решение таких задач, как завершение текста, генерация кода и резюмирование, путем указания задачи в качестве подсказки). Эта способность - внутриконтекстное обучение.\n",
        "\n",
        "Это значит, что возможно для \"вызова\" оператора может потребоваться некоторый катализатор/ключ/команда. Можно предположить, что после полного обучения трансформера для вызова оператора на тестой задаче необходимо будет скормить ему 1-4 успешных эпизода (или убедиться, что он справиться с первый эпизодом самостоятельно).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Код"
      ],
      "metadata": {
        "id": "92gyIw05vwaW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Инициализация и основные фнукции"
      ],
      "metadata": {
        "id": "rpMqgAaaxPrl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUeginZJ03Rm",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bafca9c-49e3-48af-9322-79d3c6f92e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: toymeta in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: gymnasium>=0.29.0 in /usr/local/lib/python3.10/dist-packages (from toymeta) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.29.0->toymeta) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.29.0->toymeta) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.29.0->toymeta) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.29.0->toymeta) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "# @title Скачиваем toymeta\n",
        "!pip install toymeta    # Dark Room:  https://github.com/corl-team/toy-meta-gym/blob/main/src/toymeta/dark_room.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rhJGH6W0hWR",
        "outputId": "3b8d14e1-d619-407a-fead-5cbd86fdac85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# @title Билиотеки  и выбор GPU\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from collections import deque\n",
        "from toymeta.dark_room import DarkRoom\n",
        "\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import pygame;\n",
        "from PIL import Image\n",
        "\n",
        "# Определяем устройство: CPU или GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9CmaLBku0mkt"
      },
      "outputs": [],
      "source": [
        "# @title Трансформер (GPT2)\n",
        "from transformers import GPT2Model, GPT2Config, GPT2Tokenizer\n",
        "\n",
        "class GPT2Policy(nn.Module):\n",
        "    def __init__(self, conf, action_dim, max_len=10):\n",
        "        super(GPT2Policy, self).__init__()\n",
        "        self.gpt2 = GPT2Model(conf)\n",
        "        self.action_head = nn.Linear(conf.n_embd, action_dim)\n",
        "\n",
        "    def forward(self, states):\n",
        "        outputs = self.gpt2(states)[0]\n",
        "        actions = self.action_head(outputs)\n",
        "        return actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ks_UjkCQ0w-p",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Генерация данных алгоритмом Q-Learning\n",
        "# Генерирует последовательность историй достижения агентом статического финиша из статического старта\n",
        "# Точка финиша и Старта изначально генерируется случайным образом\n",
        "# Метод: Q-Learning\n",
        "# Возвращает последовательность историй, история - последовательность состояний (state, action, reward)\n",
        "\n",
        "def generate_bandit_data(env, num_episodes, state_dim, action_dim, max_steps, best_story=False, pr=False):\n",
        "    stories = []\n",
        "\n",
        "    # Q-Learning\n",
        "    # Параметры обучения\n",
        "    # Можно попробовать брать случайные параметры как пример ~разных политик\n",
        "    alpha = 0.1      # Скорость обучения\n",
        "    gamma = 0.9      # Дисконтирующий фактор\n",
        "    epsilon = 1.0    # Начальное значение epsilon для epsilon-greedy\n",
        "    epsilon_decay = 0.995   # Темп снижения epsilon\n",
        "    epsilon_min = 0.2       # Минимальное значение epsilon\n",
        "\n",
        "    total_steps = 0\n",
        "\n",
        "    q_table = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "    for episode in range(num_episodes):\n",
        "        state, _ = env.reset()\n",
        "        done = False\n",
        "        story = []\n",
        "        step = 0\n",
        "        best_step_flag = False\n",
        "        total_reward = 0\n",
        "        start = state\n",
        "        finish = env.pos_to_state(env.goal_pos)\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            # Выбор action с использованием epsilon-greedy\n",
        "            if np.random.rand() < epsilon:\n",
        "                action = env.action_space.sample()  # Выбираем случайное действие\n",
        "            else:\n",
        "                action = np.argmax(q_table[state])  # Выбираем действие с максимальным Q-значением\n",
        "\n",
        "            next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "\n",
        "            # Отладка: Для проверки на копирование трансформером политики\n",
        "            # if episode > 0.8*num_episodes:\n",
        "            #     story.append((state, action, reward))\n",
        "\n",
        "            story.append((state, action, reward))\n",
        "            total_reward += reward\n",
        "\n",
        "            # Обновление Q-таблицы\n",
        "            best_next_action = np.argmax(q_table[next_state])\n",
        "            q_table[state, action] += alpha * (reward + gamma * q_table[next_state, best_next_action] - q_table[state, action])\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "            if not best_step_flag:\n",
        "                if reward > 0:\n",
        "                    best_step_flag = step\n",
        "\n",
        "            if terminated:\n",
        "                break\n",
        "\n",
        "            # Что если заканчивать эпизод при определенном total reward?\n",
        "            # Чтобы научить модель стоять при достижении цели\n",
        "            # if total_reward > max_steps/3:\n",
        "            #     break\n",
        "\n",
        "        # Снижение epsilon\n",
        "        epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
        "        if best_story:\n",
        "            if total_reward > 0: # or if done? (it's intereting)\n",
        "                stories.append(story)\n",
        "        else:\n",
        "            stories.append(story)\n",
        "        if pr:\n",
        "            print(f\"Episode {episode+1:3}/{num_episodes:03d} completed in {best_step_flag:3}/{step+1:03d} steps, reward {total_reward:4}, task ({start:2}->{state:2}/{finish})\")\n",
        "        total_steps+= int(best_step_flag)\n",
        "    print(f\"=== Episodes {len(stories):3}/{num_episodes:2} completed in {total_steps} total steps\")\n",
        "    return stories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usSU-8eDDhQF"
      },
      "outputs": [],
      "source": [
        "# @title Токенизация и Обучение\n",
        "\n",
        "# Токенизация данных\n",
        "# Вижу два варианта токенизировать:\n",
        "# [+] В тройки токенов (s, a, r)\n",
        "# [-] В один токен, соответствующий уникальной тройке (например, r*1 + a*10 + s*100)\n",
        "\n",
        "# Функции для преобразования состояний, действий и вознаграждений в токены\n",
        "def tokenize_three(three):\n",
        "    tokens = []\n",
        "    state, action, reward = three\n",
        "    tokens.append(action_dim + state)  # Смещаем действия\n",
        "    tokens.append(action)  # Предполагается, что action уже является токеном: небольшая хитрость, чтобы не декодировать его при подсчете loss\n",
        "    tokens.append(state_dim + action_dim + int(reward))  # Cмещаем вознаграждения\n",
        "    return tokens\n",
        "\n",
        "def tokenize_end():\n",
        "    eos_token = config.vocab_size - 1\n",
        "    return [eos_token, 0, eos_token]\n",
        "\n",
        "def tokenize_sequence(sequences):\n",
        "    tokens = []\n",
        "    for sequence in sequences:\n",
        "        for three in sequence:\n",
        "            tokens.extend(tokenize_three(three))\n",
        "        tokens.extend(tokenize_end())  # Добавляем токен конца последовательности\n",
        "    return tokens\n",
        "\n",
        "# Функция подготовки данных для обучения\n",
        "# Делим последовательность последовательностей на случайные чанки в количестве*(chunk_freq)\n",
        "# И возвращаем массив из индексов начал чанков\n",
        "def generate_chunks_num(tokens, chunk_size, chunk_freq=1):\n",
        "    # Разбиваем на chunks длиной max_len\n",
        "    # Причем не важно - начало это эпизода или где ещё\n",
        "    chunks = []\n",
        "    num_chunks = ((len(tokens)//3) // chunk_size)  # Число чанков\n",
        "    for i in range(num_chunks * chunk_freq):\n",
        "        rand = random.randint(0, len(tokens) - chunk_size*3)\n",
        "        rand-= rand % 3         # х3 - потому что tokens хранит state-action-reward\n",
        "        chunks.append(rand)\n",
        "    return chunks\n",
        "\n",
        "# Обучение\n",
        "def train_model(model, data, chunk_size, epochs=10, chunk_freq=1, lr=1e-4):\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    loss_data = []\n",
        "\n",
        "    # Подготовка данных\n",
        "    tokens = tokenize_sequence(data)\n",
        "    chunks = generate_chunks_num(tokens, chunk_size, chunk_freq)  # Индексы начала чанков\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        for chunk in tqdm(chunks):\n",
        "            # Преобразование чанка в тензор\n",
        "            batch = torch.tensor(tokens[chunk:chunk+chunk_size*3], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "            # Разделение входных данных и целевых action\n",
        "            inputs = batch[:, :-2]  # Все кроме последних action-reward\n",
        "            targets = batch[:, 1::3]  # Все action\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(inputs).squeeze(0)\n",
        "\n",
        "            # Преобразование логитов и целевых action к нужной форме\n",
        "            logits = logits[0::3,:]  # Отбираем только логиты предсказанных action (на местах входных state)\n",
        "            logits = logits.view(-1, logits.size(-1))\n",
        "            target_actions = targets.view(-1).to(device)\n",
        "\n",
        "            loss = criterion(logits, target_actions)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            loss_data.append(loss.item())\n",
        "        print(f'Epoch {epoch+1}, Loss: {total_loss}')\n",
        "\n",
        "    # Построение графика потерь\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(loss_data, label='Training Loss')\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss over Batches')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmvxn8NFbhaD"
      },
      "source": [
        "### 2) Экспериментальная установка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ci0gIxr1JkY",
        "outputId": "0e69e8b3-1121-4532-e0ce-c097ccc28a40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Agent 0 start task (R->42) ---\n",
            "=== Episodes 104/120 completed in 2259 total steps\n",
            "--- Agent 1 start task (R->43) ---\n",
            "=== Episodes 106/120 completed in 2606 total steps\n",
            "--- Agent 2 start task (R->26) ---\n",
            "=== Episodes  90/120 completed in 2191 total steps\n",
            "--- Agent 3 start task (R->4) ---\n",
            "=== Episodes 106/120 completed in 2860 total steps\n",
            "--- Agent 4 start task (R->11) ---\n",
            "=== Episodes  97/120 completed in 2567 total steps\n",
            "--- Agent 5 start task (R->26) ---\n",
            "=== Episodes  93/120 completed in 2545 total steps\n",
            "--- Agent 6 start task (R->25) ---\n",
            "=== Episodes  82/120 completed in 1833 total steps\n",
            "--- Agent 7 start task (R->34) ---\n",
            "=== Episodes  95/120 completed in 1960 total steps\n",
            "--- Agent 8 start task (R->28) ---\n",
            "=== Episodes  91/120 completed in 1936 total steps\n",
            "--- Agent 9 start task (R->14) ---\n",
            "=== Episodes  98/120 completed in 2262 total steps\n",
            "--- Agent 10 start task (R->57) ---\n",
            "=== Episodes  97/120 completed in 1922 total steps\n",
            "--- Agent 11 start task (R->57) ---\n",
            "=== Episodes  99/120 completed in 2151 total steps\n",
            "--- Agent 12 start task (R->59) ---\n",
            "=== Episodes 106/120 completed in 2341 total steps\n",
            "--- Agent 13 start task (R->61) ---\n",
            "=== Episodes  99/120 completed in 2420 total steps\n",
            "--- Agent 14 start task (R->59) ---\n",
            "=== Episodes 106/120 completed in 2406 total steps\n",
            "--- Agent 15 start task (R->52) ---\n",
            "=== Episodes  89/120 completed in 2194 total steps\n",
            "--- Agent 16 start task (R->75) ---\n",
            "=== Episodes  85/120 completed in 2392 total steps\n",
            "--- Agent 17 start task (R->14) ---\n",
            "=== Episodes  98/120 completed in 2275 total steps\n",
            "--- Agent 18 start task (R->70) ---\n",
            "=== Episodes  98/120 completed in 2528 total steps\n",
            "--- Agent 19 start task (R->30) ---\n",
            "=== Episodes  96/120 completed in 2075 total steps\n",
            "--- Agent 20 start task (R->31) ---\n",
            "=== Episodes 105/120 completed in 1977 total steps\n",
            "--- Agent 21 start task (R->20) ---\n",
            "=== Episodes 102/120 completed in 2253 total steps\n",
            "--- Agent 22 start task (R->65) ---\n",
            "=== Episodes  88/120 completed in 2041 total steps\n",
            "--- Agent 23 start task (R->5) ---\n",
            "=== Episodes  91/120 completed in 2069 total steps\n",
            "--- Agent 24 start task (R->18) ---\n",
            "=== Episodes  97/120 completed in 2381 total steps\n"
          ]
        }
      ],
      "source": [
        "### Инициализация параметров\n",
        "env_size = 9              # Размер среды DarkRoom\n",
        "state_dim = env_size**2   # Размер пространства состояний среды (9x9)\n",
        "action_dim = 5            # Размер пространства дейтсвий\n",
        "\n",
        "num_stories = 25          # Количество разных задач (разных = случайных начальных условий)\n",
        "num_episodes = 120        # Количество последовательных эпизодов в обучении одной задаче (длина истории)\n",
        "max_steps = 100           # Предел по количеству шагов в одном эпизоде (чтобы отбрасывать слишком долгие эпизоды)\n",
        "terminate_on_goal = True  # Заканчивать эпизод по достижению цели\n",
        "best_story = True         # Брать ли только оконченные эпизоды? (terminated on goal)\n",
        "random_start = True       # Случайные начальные координаты\n",
        "\n",
        "trajectory_print = False   # Вывод генерированных траекторий\n",
        "\n",
        "\n",
        "\n",
        "### Генерация историй\n",
        "# Формат\n",
        "# [-] Одна история из последовательности попыток: [(o1,a1,r1), ..., (og,ag,rg), /достиг goal -> вернулся в начало/ , (o1,a1,r1), .../-> достиг оптимальной политики/]\n",
        "# [-] Или каждая попытка по отдельности:  [[(oar)1, ... (oar)g], .../достиг оптимальной политики по задаче/, [(oar),...], /история следующих агентов-задач/...]\n",
        "# [+] Всё в одну длинную последовательность. При токенизации добавлять токен конца последовательности\n",
        "\n",
        "\n",
        "# Создаем истории обучения нескольких агентов (с разными координатами цели)\n",
        "data = []\n",
        "goal = None   # Случайные\n",
        "\n",
        "for agent in range(num_stories):\n",
        "    # Обновляем среду (координаты финиша). Каждый агент - разная задача\n",
        "    env = DarkRoom(size=env_size, goal=goal, random_start=random_start, terminate_on_goal=terminate_on_goal, render_mode=\"rgb_array\")\n",
        "    state, _ = env.reset()\n",
        "    finish = env.pos_to_state(env.goal_pos)\n",
        "\n",
        "    # Генерация последовательностей эпизодов одной задачи\n",
        "    print(f'--- Agent {agent} start task ({state if not random_start else \"R\"}->{finish}) ---')\n",
        "    data.extend(generate_bandit_data(env, num_episodes, state_dim, action_dim, max_steps, best_story=best_story, pr=trajectory_print))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qL_wErDyBvlh",
        "outputId": "3afd7e16-2eab-46a4-e2f8-378b754b9584"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training in 20 epoch:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:24<00:00, 67.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1540.361756503582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 68.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 1493.6606643795967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 69.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 1464.5096015930176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 68.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 1442.9533557891846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:24<00:00, 67.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 1422.3262394070625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 68.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 1403.6427756547928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 69.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 1388.6887826919556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 69.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 1374.5465506315231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 68.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 1358.3137737512589\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 68.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 1344.5930551290512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 68.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Loss: 1334.112991988659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 68.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Loss: 1323.5305507183075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 68.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 1311.282988190651\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 69.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Loss: 1299.4740231633186\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 68.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Loss: 1289.5823682546616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 68.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Loss: 1278.4153343439102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 68.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 1269.2364801764488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 69.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Loss: 1258.7828060388565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 69.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Loss: 1251.1116491556168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1632/1632 [00:23<00:00, 69.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Loss: 1242.373454451561\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "### Алгоритм дистилляции\n",
        "\n",
        "histories_size = 30            # Длина эпизодичности контекстов обучения\n",
        "                               # Однако, эпизоды разной длины, поэтому чанк охватывает\n",
        "chunk_size = histories_size * max_steps//8   # Средняя длинна эпизода меньше (~в 6-8 раз)\n",
        "\n",
        "# Правильнее было бы хранить эпизоды по отдельности\n",
        "# и только потом превращать в чанки нужной эпизодичности и токены\n",
        "\n",
        "chunk_freq = 8   # Количество случайных чанков в отношении к общей вместительности из таких чанков\n",
        "context_size = 3 * chunk_size\n",
        "\n",
        "epoch = 20\n",
        "\n",
        "# Инициализация модели GPT-2\n",
        "config = GPT2Config(\n",
        "    vocab_size=128,     # Примерно 128 > num_state + num_action + num_reward\n",
        "    max_position_embeddings=context_size,\n",
        "    n_positions=context_size,\n",
        "    n_ctx=context_size,\n",
        "    n_embd=256,\n",
        "    n_layer=5,\n",
        "    n_head=4,\n",
        "    n_inner=256,\n",
        "    resid_pdrop=0.1,         # Dropout rate для residuus соединений\n",
        "    attn_pdrop=0.5,          # Dropout rate для механизма внимания\n",
        "    embd_pdrop=0.1,          # Dropout для эмбеддингов\n",
        "    layer_norm_epsilon=1e-5, # Epsilon для LayerNorm\n",
        "    initializer_range=0.02,  # Начальный диапазон для весов\n",
        "    use_cache=True,          # Использовать кэширование\n",
        "    position_embedding_type=\"relative_key_query\", # Относительные позиционные эмбеддинги для ключей и запросов\n",
        "                                                  # Позволяет модели учитывать и ключевые моменты в последовательности, и их взаимосвязь\n",
        ")\n",
        "\n",
        "# model = GPT2Policy(config, action_dim)\n",
        "\n",
        "# Обучение модели\n",
        "print(f'Training in {epoch} epoch:')\n",
        "train_model(model, data, chunk_size, epoch, chunk_freq)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHh43yCB9OCk"
      },
      "source": [
        "### 3) Тестирование"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vR6TGHtN58B7"
      },
      "outputs": [],
      "source": [
        "# @title Функция тестирования\n",
        "# Тестирование\n",
        "\n",
        "def render_environment(env):\n",
        "    # Отображаем текущее состояние среды\n",
        "    frame = env.render()\n",
        "\n",
        "    # Проверяем, если состояние является изображением\n",
        "    if frame.ndim == 3 and frame.shape[2] == 3:\n",
        "        frame = np.transpose(frame, (1, 0, 2))  # Транспонируем изображение, если необходимо\n",
        "        return pygame.surfarray.make_surface(frame)\n",
        "    else:\n",
        "        raise ValueError(\"Неверный формат изображения. Проверьте метод render()\")\n",
        "\n",
        "\n",
        "\n",
        "# Тест с Визуализацией\n",
        "# gif_episode = False or num_frame - делать гифку кажыде n эпизодов\n",
        "# story       = предыстория обучения\n",
        "# best_story  = True - отбирать только истрии с reward > 0\n",
        "\n",
        "def test(model, env, num_episodes=20, max_steps=100, gif_episode=False, story = [], best_story=False):\n",
        "\n",
        "    gif_flag = False\n",
        "    if gif_episode:\n",
        "        pygame.init()\n",
        "        window_size = 600  # Установите размер окна\n",
        "        screen = pygame.display.set_mode((window_size, window_size))\n",
        "        clock = pygame.time.Clock()\n",
        "\n",
        "    # Переносим на GPU\n",
        "    model.to(device)\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        state, _ = env.reset()\n",
        "        action = 0\n",
        "        reward = 0.0\n",
        "        story.extend(tokenize_three([state, action, reward]))\n",
        "        done = False\n",
        "        step = 0\n",
        "        total_reward = 0\n",
        "\n",
        "        if gif_episode:\n",
        "            if episode % gif_episode == 0:\n",
        "                gif_text = f'Ep{episode+1} GIF saved!'\n",
        "                frames = []\n",
        "                gif_flag = True\n",
        "        if not gif_flag:\n",
        "            gif_text = ''\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            # Выбираем лучшее действие\n",
        "            input_tensor = torch.tensor(story, dtype=torch.long).unsqueeze(0).to(device)\n",
        "            logits = model(input_tensor)\n",
        "            action = torch.argmax(logits[0][-2], dim=-1).item()  # Берем только last action из под state-action-reward\n",
        "\n",
        "            # Выполняем шаг\n",
        "            next_state, reward, terminated, _, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "\n",
        "            if gif_flag:\n",
        "                # Рендерим текущее состояние среды\n",
        "                frame = render_environment(env)\n",
        "\n",
        "                # Масштабируем изображение до размера окна\n",
        "                frame = pygame.transform.scale(frame, (window_size, window_size))\n",
        "\n",
        "                # Отображаем кадр\n",
        "                screen.blit(frame, (0, 0))\n",
        "                pygame.display.flip()\n",
        "\n",
        "                # Добавляем кадр в список\n",
        "                frame_data = pygame.surfarray.array3d(frame)\n",
        "                frame_data = np.transpose(frame_data, (1, 0, 2))  # Приведение к правильному формату\n",
        "                frames.append(Image.fromarray(frame_data))\n",
        "\n",
        "                # Пауза между кадрами\n",
        "                # clock.tick(20)  # 20 FPS\n",
        "\n",
        "            if best_story:\n",
        "                if total_reward > 0.0:\n",
        "                    story.extend(tokenize_three([state, action, reward]))\n",
        "                    # print('круто, записал >')\n",
        "            else:\n",
        "                story.extend(tokenize_three([state, action, reward]))\n",
        "                # print('записал >')\n",
        "            if len(story) > context_size*3:\n",
        "                story = story[-context_size*3:]\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "            if terminated:\n",
        "                break\n",
        "        story.extend(tokenize_end())\n",
        "\n",
        "\n",
        "        print(f'Episode {episode+1:2}/{num_episodes}, Steps: {step:2}, Reward: {total_reward:4}, ' + gif_text)\n",
        "\n",
        "        if gif_flag:\n",
        "            # Сохранение GIF\n",
        "            gif_filename = f\"episode_{episode+1:03d}.gif\"\n",
        "            frames[0].save(gif_filename, save_all=True, append_images=frames[1:], optimize=False, duration=100, loop=0)\n",
        "\n",
        "    if gif_episode:\n",
        "        print('GIF\\'s saved!')\n",
        "        pygame.quit()\n",
        "\n",
        "    env.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заранее скажу, что по результатам In-Context наблюдать не смог. Анализ в выводах."
      ],
      "metadata": {
        "id": "Wah0AFZiBHa-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7J4swRcQZTWh"
      },
      "outputs": [],
      "source": [
        "# Настроки для тестов\n",
        "num_episodes = 100\n",
        "max_steps = 200\n",
        "goal = None\n",
        "# goal = (8,6)\n",
        "best_story = True     # Сохранять в историю (контекст) только успешные эпизоды\n",
        "gif_episode = False    # Создавать гиф на каждый эпизод"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRkVOQczXs5X"
      },
      "outputs": [],
      "source": [
        "# Тест новой задачи\n",
        "env = DarkRoom(size=9, goal=goal, random_start=random_start, terminate_on_goal=terminate_on_goal, render_mode=\"rgb_array\")  # Обновились координаты goal\n",
        "\n",
        "test(model, env, num_episodes, max_steps, gif_episode, story=[], best_story=best_story)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZJPZmCTEVvW"
      },
      "source": [
        "Если долго не может найти цель, попробуем первую историю генерировать как показательную:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "К сожалению, у следующего кода под самый конец моих экспериментов (под кульминацию) появилась ошибка связанная с девайсом CUDA, которая ломает весь колаб. Разобраться и исправить, увы, не успел."
      ],
      "metadata": {
        "id": "iJkbnJBnxOtp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7awP0LUa21z"
      },
      "outputs": [],
      "source": [
        "# Тест новой задачи\n",
        "# с предыстрией начинающего успешного агента😎\n",
        "\n",
        "env = DarkRoom(size=9, goal=goal, random_start=random_start, terminate_on_goal=terminate_on_goal, render_mode=\"rgb_array\")  # Обновились координаты goal\n",
        "\n",
        "pre_episodes = 20     # Количество эпизодов успешного агента\n",
        "pre_steps = max_steps # Число последних шагов успещного агента, из которых состоит предыстория\n",
        "prestory = generate_bandit_data(env, pre_episodes, state_dim, action_dim, max_steps, best_story, pr=True)[-max_steps:]\n",
        "\n",
        "test(model, env, num_episodes, max_steps, gif_episode, story=tokenize_sequence(prestory), best_story=best_story)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Выводы"
      ],
      "metadata": {
        "id": "-UD1AHhPwklZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Почему не полулось обнаружить In-Context\n",
        "1) Мало эпох обучения\n",
        "- ближе к дедлайну стал дольше обучать (эпох 30-40), видеть прогресс модели, но доэксперименировать не удалось\n",
        "\n",
        "2) Мало данных\n",
        "- увеличивал до 100 историй по 100 эпизодов\n",
        "- можно увеличить число задач до 100 случайных\n",
        "(максимум есть 81 одна разная задача)\n",
        "\n",
        "3) Не верно организованы батчи\n",
        "\n",
        "- батчи имеют неизвестное число эпизодов (но строгий размер)\n",
        "- батчи начинаются со случайного токена\n",
        "- батчи объединяют последовательность разных историй\n",
        "\n",
        "4) Не верные гиперпараметры и модель\n",
        "- длина батчей ~ количество эпизодов не отражают \"обучение\"\n",
        "- сама модель трансформера неудачная (число слоев, голов, эмбэдингов, архитектура...)\n",
        "\n",
        "5) Плохо подаются данные\n",
        "- не различает 3 модальности\n",
        "- возможно стоит по другому токенизировать\n",
        "- или использовать архитектуру с мультимодальностью\n",
        "\n",
        "6) Сами обучающие данные плохо отражают обучение\n",
        "- возможно QL не качественно отражает обучение методом проб и ошибок\n",
        "\n",
        "7) Тестирование\n",
        "- Возможно трансформеру не хватает катализатора/ключа/команды, чтобы вызвать оператор \"обучения\". Решение - давать ему начало (3-4 эпизода) из успешной истории\n",
        "\n"
      ],
      "metadata": {
        "id": "yGeNu0JH18Ud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Идеи и Гипотезы"
      ],
      "metadata": {
        "id": "0-oFB-Irz2eu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если принять интерпретацию работы нейросетей и, в частности, трансформеров:\n",
        "- каждый новый слой имеет в своем эмбэдинге более абстрактные и общие представления.\n",
        "\n",
        "Что если сначала обучать модель самим эпизодам, и оптимизировать её до представлений эпизода (начало и конец с наградой, токен конца эпизода, понимание \"стенок\", простые шаблоны движения, любопытсво (стохастичность)). То есть, научить её фантазировать развитие эпизода вплоть до `reward=1`. И только после обучения всем базовым (\"приземленным\") представлениям, начать давать ей целые истории, чтобы она начала искать более абстрактные/общие представления, эпизодическую связь, в поисках того самого \"оператора обучения\".\n",
        "\n",
        "Поэкспериментировать с этой гипотезой не успел."
      ],
      "metadata": {
        "id": "nULT8pXaz9vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Часть 2: Scientist**"
      ],
      "metadata": {
        "id": "Qn-VUIBBxPPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Задание:**\n",
        "Расскажите о трех статьях с A* конференций по RL, которые зацепили вас больше всего за последние пару лет..."
      ],
      "metadata": {
        "id": "Frf2uaNSSZ0t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Я аспирант и выбрал специальность [5.12.4. Когнитивное моделировани](https://vak.minobrnauki.gov.ru/uploader/loader?type=17&name=92259542002&f=15363) (п.1/8/11/12), и мой интерес обобщается созданием когнитивного ИИ.\n",
        "\n",
        "Иначе говоря, мне интересны в первую очередь именно теоретические модели человеческого разума (или живых существ), и уже на основе этих представлений и моделей формализовать программные модели ИИ.\n",
        "\n",
        "По этому, последний год мне были интересны более абстрактные статьи, которые дают мне общую картину и пространство для идей, которые позволяют лучше интерпретировать собственное мышление и проецировать на современные модели нейросетей, чтобы уже на основе этого понимания формализовать новые когнивтиные карты и модели разума/ИИ.\n",
        "\n",
        "Пример теоретических:\n",
        "- [Байесовская модель](https://royalsocietypublishing.org/doi/pdf/10.1098/rsfs.2022.0029) мозга\n",
        "  - Описывает мозг как пространство убеждений, которые обновляются в процессе получения новой информации (связанной с \"неожиданностью\" - отличием информации от предсказываемой убеждениями)\n",
        "- Принципы [теории разума](https://www.frontiersin.org/journals/systems-neuroscience/articles/10.3389/fnsys.2016.00084/full)\n",
        "  - Описывает знания человека в виде метапространства концепций (\"паутины\" отношений объектов, явлений и идей), концеции в которой имеют когнитивную иерархию: от \"приземленных\" представлений объектов и явлений до абстрактных представлений идей (тут можно вспомнить обобщающую способность тех же трансформеров, или автоэнкодеров), которые проявляются как нисходящие и восходящие сигналы в биологических НС.\n",
        "- Модель двойного процесса\n",
        "  - Мозг действует в двух \"режимах\": Система 1, выполняющая уже известные обученные операции быстро и бессознательно (как готовая обученная нейросеть), и Система 2, выделяющая внимание при встрече с \"неожиданностью\" для сознательных умственных усиличий по обновлению \"предсказательной машины\" (обновлению убеждений)\n",
        "- [Принцип свободной энергии](https://www.sciencedirect.com/science/article/pii/S1571064517301409)\n",
        "  - Он гласит о том, что живые существа, как самоорганизующиеся системы, стремятся к поглощению информации из окружающей среды (негэнтропии) для увеличения собственной упорядоченности, самосохранения. Если углубляться, этот принцип по сути описывает RL, но характеризует причины появления живых систем и \"разума\" через естественный отбор и фундаментальные физические принципы.\n",
        "- И другие модели из когнитивных наук (тоже \"внимание\").\n",
        "\n",
        "\n",
        "Если говорить про более прикладныее RL статьи, самой яркой вспомнил:\n",
        "- [Модель мира](https://arxiv.org/abs/2301.04104) (и аналогичные статьи)\n",
        "  - сама идея вдохновлена человеческим мышлением - способностью моделировать мир в воображении, заранее делать предсказания последствий каких-либо действий, и постепенно обучаться на все том же методе проб и ошибок, но уже обновляя механизмы модели мира (познание мира). Это сильно позволяет ускорять обучение, и цепляет это по двум причинам:\n",
        "    - как минимум, каждый любитель точных наук пользуется такой способностью\n",
        "    - потому что, такой метод позволяет быстрее обучаться, дел\n",
        "    - нейросеть это универсальная функция, которую можно по шажочкам оптимизировать до искомой. Функция это практически тоже самое что и модель. Значит, любое представление объектов и явлений мира явлется моделью, ну или субмоделью в общей модели мира. Поэтому, как и человека, такую нейросеть теоретически можно медленно обучать субмоделям (объектам, явлениям, действиям), собирая целую картину. Но следствие, которое сводит меня с ума в этой идее, что представление в модели мира самого себя (того кто воспроизводит эту модель) является той рефлексией порождающей самосознание в разумных существах.\n",
        "    - и это по сути снова отражает принцип свободной энергии, упомянутый ранее: живые системы поглащают информацию об окружающем мире (делая его для себя предсказуемым), для того чтобы адаптироваться (сохранить собственную упорядоченность, ну то есть выжить). А значит любой RL алгоритм универсально стремиться выстроить как можно более подробную модель мира (или ограниченно - модель окружающей его среды, словно обучение сходится к отражению)\n",
        "    - а ещё очень цепляет применение таких алгоритмов на симмуляторах-песочницах с открытым миром по типу MineCraft\n",
        "\n",
        "Меня также зацепила одна идея, на основе статьи к этому заданию ([In-context RL with AD](https://arxiv.org/abs/2210.14215/)):\n",
        "- факт того, что нейросеть обучилась \"оператор\"\n",
        "\n",
        "Другими словами, нейросеть научилась какому-то действию. И ведь если задуматься, большинство действий можно представить в виде инструкций из простых базовых действий, команд (субфункций). GPT научился этим базовым действиям работы с текстом, но, имея некоторую модель мира, он также научился моделировать более \"реальные\" действия в виде текстовых последовательностей.\n",
        "\n",
        "Из этой мысли появляется много интересных общих идей:\n",
        "- Можно ли у GPT развить модель мира?\n",
        "- Можно рекурсивно замкнуть GPT с промтом создания новых действий на основе старых?\n",
        "- Получается, глубокие сети имеют способность хранить не только \"знания\", но и операторы (действия, с конкретной целью). Это спускает концепции \"знаний\", как вывода нейросети, с действиями. То есть, часть выходных токенов нейросети можно напрямую подключать к действиям, а часть оставлять как новое знание (мысль) и возвращать на вход. Ну эта идея у меня уже связана непосредственно с тем, что я путаюсь реализовать в своей диссертации.\n",
        "\n",
        "\n",
        "\n",
        "Тематикой своей диссертации я выбрал: \"Моделирование рефлексивного мышления искусственных агентов в обучении с подкреплением\". Этим летом начал продумывать методы эксперимента, и чувствую, что направление исследований Вашей команды (Адаптивные агенты) очень перспективно взаимосвязано с моей темой. Поэтому хотелось бы пообщаться на эту тему как ученые и помочь друг другу в реализации идей.\n",
        "\n"
      ],
      "metadata": {
        "id": "hLzuSm1JKFhA"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rpMqgAaaxPrl"
      ],
      "authorship_tag": "ABX9TyPoN6Q5OJxK0w0Wn28rY+pX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}